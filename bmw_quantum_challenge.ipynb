{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "11b4d92a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On branch main\n",
      "Your branch is up to date with 'origin/main'.\n",
      "\n",
      "Changes to be committed:\n",
      "  (use \"git reset HEAD <file>...\" to unstage)\n",
      "\n",
      "\t\u001b[32mnew file:   bmw_quantum_challenge.ipynb\u001b[m\n",
      "\t\u001b[32mnew file:   metrics/resnet/avg_acc_test.npy\u001b[m\n",
      "\t\u001b[32mnew file:   metrics/resnet/avg_acc_train.npy\u001b[m\n",
      "\t\u001b[32mnew file:   metrics/resnet/avg_loss_test.npy\u001b[m\n",
      "\t\u001b[32mnew file:   metrics/resnet/avg_loss_train.npy\u001b[m\n",
      "\t\u001b[32mnew file:   metrics/resnet_q_angular_depth1/avg_acc_test.npy\u001b[m\n",
      "\t\u001b[32mnew file:   metrics/resnet_q_angular_depth1/avg_acc_train.npy\u001b[m\n",
      "\t\u001b[32mnew file:   metrics/resnet_q_angular_depth1/avg_loss_test.npy\u001b[m\n",
      "\t\u001b[32mnew file:   metrics/resnet_q_angular_depth1/avg_loss_train.npy\u001b[m\n",
      "\t\u001b[32mnew file:   metrics/resnet_q_angular_depth5/avg_acc_test.npy\u001b[m\n",
      "\t\u001b[32mnew file:   metrics/resnet_q_angular_depth5/avg_acc_train.npy\u001b[m\n",
      "\t\u001b[32mnew file:   metrics/resnet_q_angular_depth5/avg_loss_test.npy\u001b[m\n",
      "\t\u001b[32mnew file:   metrics/resnet_q_angular_depth5/avg_loss_train.npy\u001b[m\n",
      "\n",
      "Changes not staged for commit:\n",
      "  (use \"git add <file>...\" to update what will be committed)\n",
      "  (use \"git checkout -- <file>...\" to discard changes in working directory)\n",
      "\n",
      "\t\u001b[31mmodified:   bmw_quantum_challenge.ipynb\u001b[m\n",
      "\n",
      "Untracked files:\n",
      "  (use \"git add <file>...\" to include in what will be committed)\n",
      "\n",
      "\t\u001b[31m.gitignore.txt\u001b[m\n",
      "\t\u001b[31m.ipynb_checkpoints/\u001b[m\n",
      "\t\u001b[31mUntitled.ipynb\u001b[m\n",
      "\t\u001b[31mdefect_data.zip\u001b[m\n",
      "\t\u001b[31mdefect_data/\u001b[m\n",
      "\t\u001b[31mmodels/\u001b[m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!git add bmw_quantum_challenge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "845e4207",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install torchvision\n",
    "!pip install sagemaker"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b1c5bfb",
   "metadata": {},
   "source": [
    "### Import stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a143770b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch import optim\n",
    "\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "import torchvision.models as models\n",
    "\n",
    "from torch.utils.data import random_split\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import ImageFolder\n",
    "\n",
    "import torch.nn as nn\n",
    "import pathlib\n",
    "\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dadf0a11",
   "metadata": {},
   "source": [
    "### load data from S3 to folder of sagemaker instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f602d281",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "\n",
    "# When running on SageMaker, need execution role\n",
    "from sagemaker import get_execution_role\n",
    "role = get_execution_role()\n",
    "\n",
    "# Declare bucket name, remote file, and destination\n",
    "s3_bucket = \"amazon-braket-a79a20b5e0b4\"\n",
    "orig_file = 'defect_data.zip'\n",
    "dest_file = './defect_data.zip'\n",
    "\n",
    "# Connect to S3 bucket and download file\n",
    "s3 = boto3.resource('s3')\n",
    "s3.Bucket(s3_bucket).download_file(orig_file, dest_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "030caa9b",
   "metadata": {},
   "source": [
    "### unzip defect_data.zip "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da8973f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from zipfile import ZipFile\n",
    "\n",
    "# Create a ZipFile Object and load sample.zip in it\n",
    "with ZipFile('defect_data.zip', 'r') as zipObj:\n",
    "   # Extract all the contents of zip file in current directory\n",
    "   zipObj.extractall('./defect_data')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c8ae5df",
   "metadata": {},
   "source": [
    "### Data preparation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55dc2452",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_test_data(img_path, img_set_size = 40e3, test_set_ratio = 0.2):\n",
    "    \"\"\"\n",
    "    Create train and test data with PyTorchs ImageFolder class.  \n",
    "    \"\"\"\n",
    "\n",
    "    resolution = (227,227)\n",
    "    \n",
    "    img_dataset = datasets.ImageFolder(\n",
    "        root=img_path,\n",
    "        transform=transforms.Compose([\n",
    "            transforms.Resize(resolution), # do not have to resize because all imgs are on 227x227\n",
    "            transforms.ToTensor(),\n",
    "            # maps values from [0, 1] to [-1,1]\n",
    "            # 0.5 mean and 0.5 std deviation for each channel is a standard choice\n",
    "            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)) \n",
    "        ]))\n",
    "    \n",
    "    # restrict size of data set\n",
    "    # take n random indices out of full img_dataset size\n",
    "    random_indices = random.sample(range(len(img_dataset)), img_set_size)\n",
    "\n",
    "    img_dataset_subset = torch.utils.data.Subset(img_dataset, random_indices)\n",
    "    \n",
    "    # split data set into train and test set\n",
    "    test_set_size = int(test_set_ratio * len(img_dataset_subset))\n",
    "    train_set_size = len(img_dataset_subset) - test_set_size   \n",
    "    train_set, test_set = random_split(img_dataset_subset, [train_set_size, test_set_size], generator=torch.Generator().manual_seed(42))\n",
    "    \n",
    "    # with attribute class_to_idx we get a mapping from classes to labels. We invert the dict subsequently.\n",
    "    label_to_class_dict = {value: key for key, value in img_dataset.class_to_idx.items()}\n",
    "\n",
    "    return train_set, test_set, label_to_class_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2a85493",
   "metadata": {},
   "source": [
    "### load data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eda4ac81",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = './defect_data'\n",
    "train_set, test_set, label_to_class_dict = get_train_test_data(img_path, img_set_size = 100)\n",
    "\n",
    "\n",
    "BATCH_SIZE = 32 \n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_set,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_set,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1e701a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "832dc0ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(test_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e10b3b85",
   "metadata": {},
   "source": [
    "### train functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fd755f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_plain_accuracy(y_pred, y_true):\n",
    "    return (y_pred.argmax(dim=1) == y_true).float().mean()\n",
    "\n",
    "\n",
    "def eval_test_set(model, best_loss, model_name, run_idx):\n",
    "    print(\"### Eval test set ###\")\n",
    "\n",
    "    model.eval()\n",
    "    loss_fn = torch.nn.CrossEntropyLoss(reduction = 'mean')\n",
    "    \n",
    "    y_test_pred = torch.tensor([]).float()\n",
    "    y_test_true = torch.tensor([]).long()  \n",
    "    \n",
    "    # forward pass is faster with torch.no_grad()\n",
    "    with torch.no_grad(): \n",
    "            \n",
    "        for x_test_batch, y_test_true_batch in test_loader:\n",
    "            \n",
    "            y_test_pred_batch = model(x_test_batch)\n",
    "            \n",
    "            y_test_pred = torch.cat([y_test_pred, y_test_pred_batch])\n",
    "            y_test_true = torch.cat([y_test_true, y_test_true_batch])            \n",
    "                    \n",
    "    loss_test = loss_fn(y_test_pred, y_test_true)\n",
    "    acc_test = get_plain_accuracy(y_test_pred, y_test_true)\n",
    "\n",
    "    print(f\"Loss test: {loss_test:.3f}\")\n",
    "    print(f\"Accuracy test: {acc_test:.3f}\")  \n",
    "\n",
    "    # save best_model\n",
    "    if loss_test < best_loss:\n",
    "        state = {\n",
    "            'state_dict': model.state_dict()\n",
    "        }\n",
    "        torch.save(state, f'./models/{model_name}_best_model_run_{run_idx}.h5')\n",
    "        best_loss = loss_test\n",
    "        \n",
    "    print(\"#####################\\n\")    \n",
    "    return best_loss, loss_test, acc_test  \n",
    "\n",
    "\n",
    "def train(model, num_epochs, run_idx, model_name=\"resnet\"):\n",
    "    \"\"\"Train function\"\"\"\n",
    "    \n",
    "\n",
    "    # define loss and optimizer\n",
    "    loss_fn = torch.nn.CrossEntropyLoss(reduction = 'mean')\n",
    "    optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "    acc_train_list = []\n",
    "    loss_train_list = []    \n",
    "    \n",
    "    acc_test_list = []    \n",
    "    loss_test_list = []   \n",
    "    \n",
    "    best_loss = 10e3\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "\n",
    "        print(f'### Epoch {epoch} ###\\n')\n",
    "\n",
    "        for idx, (x_train, y_true) in enumerate(train_loader):\n",
    "\n",
    "            model.train()\n",
    "            \n",
    "            print(f'Batch iter/total {idx}/{len(train_loader)-1}')\n",
    "            # zero the gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # do one forward pass\n",
    "            y_pred = model(x_train)             \n",
    "\n",
    "            # calculate the loss\n",
    "            loss = loss_fn(y_pred, y_true)\n",
    "            acc_train = get_plain_accuracy(y_pred, y_true)\n",
    "\n",
    "            print(f\"Loss train: {loss:.3f}\")\n",
    "            print(f\"Accuracy train: {acc_train:.3f}\\n\")\n",
    "\n",
    "            # get gradients with respect to that loss\n",
    "            loss.backward()\n",
    "\n",
    "            # actual optimizing step\n",
    "            optimizer.step()\n",
    "\n",
    "            acc_train_list.append(acc_train.item())\n",
    "            loss_train_list.append(loss.item())\n",
    "        \n",
    "            # eval test set every 5 iters\n",
    "            if ((idx + 1) % 5) == 0:\n",
    "                best_loss, loss_test, acc_test = eval_test_set(model, best_loss, model_name,run_idx)\n",
    "                \n",
    "                acc_test_list.append(acc_test.item())\n",
    "                loss_test_list.append(loss_test.item())\n",
    "                \n",
    "    return acc_train_list, acc_test_list, loss_train_list, loss_test_list\n",
    "\n",
    "\n",
    "def plot_stuff(data_, title, plot_each_metric=False):\n",
    "    \n",
    "    data = data_.mean(axis=0)\n",
    "    std = data_.std(axis=0)\n",
    "    \n",
    "    plt.figure(figsize=(9,5))\n",
    "    plt.title(title)\n",
    "    plt.plot(data)\n",
    "    \n",
    "    if plot_each_metric:\n",
    "        plt.plot(data_.T)\n",
    "    \n",
    "    plt.fill_between(range(len(data)), data - std, data + std, color='tab:blue', alpha=0.15)\n",
    "                 \n",
    "    plt.grid()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95b6054f",
   "metadata": {},
   "source": [
    "### load pretrained resnet 18 and freeze all conv layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f22cf2c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def run_experiment(num_runs, num_epochs, nn_type, q_depth=None):\n",
    "    # start training process and measure time duration\n",
    "    start_time = time.time()\n",
    "\n",
    "    avg_acc_train = np.array([])\n",
    "    avg_acc_test = np.array([])\n",
    "\n",
    "    avg_loss_train = np.array([])\n",
    "    avg_loss_test = np.array([])\n",
    "\n",
    "    for run_idx in range(num_runs):\n",
    "\n",
    "        # load on ImageNet pretrained resnet18\n",
    "        model = models.resnet18(pretrained=True)\n",
    "\n",
    "        # freeze all layers\n",
    "        for name, param in model.named_parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "        # attach new last classic or quantum layer\n",
    "        if nn_type == 'classic':\n",
    "            model.fc = nn.Linear(512, 2)  \n",
    "            model_name=\"resnet\"\n",
    "            \n",
    "        elif nn_type == 'angular':\n",
    "            model.fc = QuantumNetAngularEmbedding(q_depth = q_depth)\n",
    "            model_name=f\"resnet_q_angular_depth{q_depth}\"\n",
    "            \n",
    "        elif nn_type == 'amplitude':\n",
    "            model.fc = QuantumNetAmplitudeEmbedding(n_qubits=9, q_depth=q_depth)\n",
    "            model_name=f\"resnet_q_amplitude_depth{q_depth}\"    \n",
    "            \n",
    "        if  run_idx == 0:  \n",
    "            print(f'########## {model_name} ##########')\n",
    "        print(f'\\n########## run {run_idx} ##########\\n')\n",
    "\n",
    "        acc_train, acc_test, loss_train, loss_test = train(model=model, num_epochs = num_epochs, run_idx= run_idx,model_name=model_name)\n",
    "\n",
    "        avg_acc_train = np.vstack([avg_acc_train, np.array(acc_train)]) if avg_acc_train.size else np.array(acc_train)  \n",
    "        avg_acc_test = np.vstack([avg_acc_test, np.array(acc_test)]) if avg_acc_test.size else np.array(acc_test)  \n",
    "\n",
    "        avg_loss_train = np.vstack([avg_loss_train, np.array(loss_train)]) if avg_loss_train.size else np.array(loss_train)  \n",
    "        avg_loss_test = np.vstack([avg_loss_test, np.array(loss_test)]) if avg_loss_test.size else np.array(loss_test)        \n",
    "\n",
    "    total_time = time.time() - start_time\n",
    "\n",
    "    print(f'total time taken {total_time:.2f}\\n')\n",
    "    \n",
    "    \n",
    "    # create folder if not exists\n",
    "    pathlib.Path(f\"./metrics/{model_name}\").mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # store metrics\n",
    "    np.save(f'./metrics/{model_name}/avg_acc_test.npy', avg_acc_test)\n",
    "    np.save(f'./metrics/{model_name}/avg_acc_train.npy', avg_acc_train)\n",
    "\n",
    "    np.save(f'./metrics/{model_name}/avg_loss_train.npy', avg_loss_train)\n",
    "    np.save(f'./metrics/{model_name}/avg_loss_test.npy', avg_loss_test)\n",
    "    \n",
    "    return avg_acc_train.T, avg_acc_test.T, avg_loss_train.T, avg_loss_test.T\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c84941b9",
   "metadata": {},
   "source": [
    "## Train CNN classically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28229ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_runs = 3\n",
    "num_epochs = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a74c42f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "avg_acc_train, avg_acc_test, avg_loss_train, avg_loss_test = run_experiment(num_runs, num_epochs, nn_type='classic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fb979e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "avg_acc_test = np.load('./metrics/resnet/avg_acc_test.npy')\n",
    "avg_acc_train = np.load('./metrics/resnet/avg_acc_train.npy')\n",
    "\n",
    "avg_loss_train = np.load('./metrics/resnet/avg_loss_train.npy')\n",
    "avg_loss_test = np.load('./metrics/resnet/avg_loss_test.npy')\n",
    "\n",
    "print(f'max average test accuracy {max(avg_acc_test.mean(axis=0)):.3f}')\n",
    "\n",
    "plot_stuff(avg_acc_test, title = 'Acc test')\n",
    "plot_stuff(avg_acc_train, title = 'Acc train')\n",
    "\n",
    "plot_stuff(avg_loss_train, title = 'Loss train')\n",
    "plot_stuff(avg_loss_test, title = 'Loss test')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb47dc8f",
   "metadata": {},
   "source": [
    "### Quantum Net "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e242802",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pennylane\n",
    "import pennylane as qml\n",
    "from pennylane import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d9019e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters of quantum net\n",
    "\n",
    "n_qubits = 4        \n",
    "\n",
    "init_param_spread = 0.01 # Initial spread of random quantum weights\n",
    "\n",
    "dev = qml.device(\"braket.local.qubit\", wires=n_qubits)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcd4f752",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def entangling_layer(n_qubits = n_qubits, pattern = 'chain'):\n",
    "    \"\"\"pattern in ('chain', 'ring', 'all_to_all')\"\"\"\n",
    "    \n",
    "    if pattern not in ('chain', 'ring', 'all_to_all', 'random'):\n",
    "        pattern = 'chain'\n",
    "    if pattern is not 'random':\n",
    "        qml.broadcast(qml.CNOT, wires = list(range(n_qubits)), pattern = pattern)\n",
    "    else:\n",
    "        q_idx_list = list(range(n_qubits))\n",
    "        np.random.shuffle(q_idx_list)\n",
    "        for i in range(n_qubits - 1):\n",
    "            qml.CNOT(wires = [q_idx_list[i], q_idx_list[i + 1]])\n",
    "        qml.CNOT(wires = [q_idx_list[-1], q_idx_list[0]])\n",
    "\n",
    "def H_layer(nqubits):\n",
    "    \"\"\"Layer of single-qubit Hadamard gates.\n",
    "    \"\"\"\n",
    "    for idx in range(nqubits):\n",
    "        qml.Hadamard(wires=idx)\n",
    "\n",
    "\n",
    "def RY_layer(w):\n",
    "    \"\"\"Layer of parametrized qubit rotations around the y axis.\n",
    "    \"\"\"\n",
    "    for idx, element in enumerate(w):\n",
    "        qml.RY(element, wires=idx)\n",
    "\n",
    "def amplitude_embedding(q_input_features, n_qubits = n_qubits):\n",
    "    \"\"\"Transfers a given input feature into a quantum statevector. 2**9 = 512\"\"\"\n",
    "\n",
    "    \n",
    "    assert len(q_input_features) == 2**n_qubits, \"Input Features must be of dimension 2**n_qubits\"\n",
    "    \n",
    "    wires_list = list(range(n_qubits))\n",
    "    \n",
    "    # TODO: replace equality comparison to one with tolerance\n",
    "    normalize = not (np.linalg.norm(q_input_features) == 1)\n",
    "            \n",
    "    qml.templates.AmplitudeEmbedding(features = q_input_features, \n",
    "                                     wires = wires_list, \n",
    "                                     normalize = normalize) \n",
    "        \n",
    "@qml.qnode(dev, interface=\"torch\")\n",
    "def quantum_net(q_input_features, q_weights_flat):\n",
    "    \"\"\"\n",
    "    The variational quantum circuit.\n",
    "    \"\"\"\n",
    "\n",
    "    # Reshape weights\n",
    "    q_weights = q_weights_flat.reshape(q_depth, n_qubits)\n",
    "\n",
    "    # Start from state |+> , unbiased w.r.t. |0> and |1>\n",
    "    H_layer(n_qubits)\n",
    "\n",
    "    # Embed features in the quantum node\n",
    "    RY_layer(q_input_features)\n",
    "\n",
    "    # Sequence of trainable variational layers\n",
    "    for k in range(q_depth):\n",
    "        entangling_layer(n_qubits = n_qubits, pattern = 'ring')\n",
    "        RY_layer(q_weights[k])\n",
    "\n",
    "    # Expectation values in the Z basis\n",
    "    exp_vals = [qml.expval(qml.PauliZ(position)) for position in range(n_qubits)]\n",
    "    return tuple(exp_vals)\n",
    "\n",
    "@qml.qnode(dev, interface=\"torch\")\n",
    "def quantum_net_amplitude(q_input_features, q_weights_flat):\n",
    "    \"\"\"\n",
    "    The variational quantum circuit with amplitude embedding\n",
    "    \"\"\"\n",
    "\n",
    "    # Reshape weights\n",
    "    q_weights = q_weights_flat.reshape(q_depth, n_qubits)\n",
    "\n",
    "    amplitude_embedding(q_input_features, n_qubits)\n",
    "\n",
    "    # Sequence of trainable variational layers\n",
    "    for k in range(q_depth):\n",
    "        entangling_layer(n_qubits = n_qubits, pattern = 'ring')\n",
    "        RY_layer(q_weights[k])\n",
    "\n",
    "    # Expectation values in the Z basis\n",
    "    exp_vals = [qml.expval(qml.PauliZ(position)) for position in range(n_qubits)]\n",
    "    \n",
    "    # Why do we return tuple here?\n",
    "    return tuple(exp_vals)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8028ce9d",
   "metadata": {},
   "source": [
    "#### draw circuit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04cea901",
   "metadata": {},
   "outputs": [],
   "source": [
    "q_depth = 1\n",
    "n_qubits = 4\n",
    "q_input_features = (torch.rand(n_qubits) * 2 - 1) * np.pi / 2\n",
    "q_weights_flat = torch.randn(q_depth * n_qubits)\n",
    "\n",
    "# evaluation of the circuit is necessary to draw the circuit \n",
    "result = quantum_net(q_input_features, q_weights_flat)\n",
    "\n",
    "print(quantum_net.draw())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2d45081",
   "metadata": {},
   "outputs": [],
   "source": [
    "# amplitude embedding \n",
    "n_qubits = 9\n",
    "q_input_features = torch.randn(2 ** n_qubits)\n",
    "\n",
    "q_weights_flat = torch.randn(q_depth * n_qubits)\n",
    "\n",
    "# evaluation of the circuit is necessary to draw the circuit \n",
    "dev = qml.device(\"braket.local.qubit\", wires=n_qubits)\n",
    "\n",
    "print(q_input_features.shape)\n",
    "\n",
    "result = quantum_net_amplitude(q_input_features, q_weights_flat)\n",
    "\n",
    "# print(quantum_net_amplitude.draw())\n",
    "\n",
    "# result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "add0b987",
   "metadata": {},
   "outputs": [],
   "source": [
    "class QuantumNetAngularEmbedding(nn.Module):\n",
    "    \"\"\"\n",
    "    Torch module implementing the *dressed* quantum net.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, q_depth):\n",
    "        \"\"\"\n",
    "        Definition of the *dressed* layout.\n",
    "        \"\"\"\n",
    "\n",
    "        super().__init__()\n",
    "        self.pre_net = nn.Linear(512, n_qubits)\n",
    "        self.q_params = nn.Parameter(init_param_spread * torch.randn(q_depth * n_qubits))\n",
    "        self.post_net = nn.Linear(n_qubits, 2)\n",
    "\n",
    "    def forward(self, input_features):\n",
    "        \"\"\"\n",
    "        Defining how tensors are supposed to move through the *dressed* quantum\n",
    "        net.\n",
    "        \"\"\"\n",
    "\n",
    "        # obtain the input features for the quantum circuit\n",
    "        # by reducing the feature dimension from 512 to 4\n",
    "        pre_out = self.pre_net(input_features)\n",
    "        q_in = torch.tanh(pre_out) * np.pi / 2.0\n",
    "\n",
    "        # Apply the quantum circuit to each element of the batch and append to q_out\n",
    "        q_out = torch.Tensor(0, n_qubits)\n",
    "        q_out = q_out.to(device)\n",
    "        for elem in q_in:\n",
    "            q_out_elem = quantum_net(elem, self.q_params).float().unsqueeze(0)\n",
    "            q_out = torch.cat((q_out, q_out_elem))\n",
    "\n",
    "        # return the two-dimensional prediction from the postprocessing layer\n",
    "        return self.post_net(q_out)\n",
    "    \n",
    "class QuantumNetAmplitudeEmbedding(nn.Module):\n",
    "    \"\"\"\n",
    "    Torch module implementing the *dressed* quantum net.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, n_qubits, q_depth):\n",
    "        \"\"\"\n",
    "        Definition of the *dressed* layout.\n",
    "        \"\"\"\n",
    "\n",
    "        super().__init__()\n",
    "        \n",
    "        self.q_params = nn.Parameter(init_param_spread * torch.randn(q_depth * n_qubits))\n",
    "\n",
    "    def forward(self, input_features):\n",
    "        \"\"\"\n",
    "        Defining how tensors are supposed to move through the *dressed* quantum\n",
    "        net.\n",
    "        \"\"\"\n",
    "\n",
    "        # Apply the quantum circuit to each element of the batch and append to q_out\n",
    "        q_out = torch.Tensor(0, n_qubits )\n",
    "        q_out = q_out.to(device)\n",
    "        \n",
    "        # iterate over each element of the batch\n",
    "        for elem in input_features:\n",
    "            q_out_elem = quantum_net_amplitude(elem, self.q_params).float().unsqueeze(0)\n",
    "            q_out = torch.cat((q_out, q_out_elem))\n",
    "\n",
    "        # restrict to first two dimensions and ignore the rest\n",
    "        return q_out[...,:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc129867",
   "metadata": {},
   "source": [
    "### Train Quantum CNN with angular embedding for different depth sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8d0740c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for q_depth in [1]:\n",
    "\n",
    "    q_avg_acc_train, q_avg_acc_test, q_avg_loss_train, q_avg_loss_test = run_experiment(num_runs, num_epochs, nn_type = 'angular', q_depth = q_depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76fd04a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for q_depth in [1,5]:\n",
    "    \n",
    "    model_name=f\"resnet_q_angular_depth{q_depth}\"\n",
    "    \n",
    "    # load quantum metrics\n",
    "    q_avg_acc_test = np.load(f'./metrics/{model_name}/avg_acc_test.npy')\n",
    "    q_avg_acc_train = np.load(f'./metrics/{model_name}/avg_acc_train.npy')\n",
    "\n",
    "    q_avg_loss_train = np.load(f'./metrics/{model_name}/avg_loss_train.npy')\n",
    "    q_avg_loss_test = np.load(f'./metrics/{model_name}/avg_loss_test.npy')\n",
    "    \n",
    "    print(f'#### DEPTH {q_depth} ####')\n",
    "#     print(q_avg_acc_test)\n",
    "    \n",
    "    print(f'max average test accuracy {max(q_avg_acc_test.mean(axis=1)):.3f}')\n",
    "\n",
    "    plot_stuff(q_avg_acc_test, title = 'Acc test',plot_each_metric=False)\n",
    "    plot_stuff(q_avg_loss_test, title = 'Loss test',plot_each_metric=False)\n",
    "    \n",
    "    plot_stuff(q_avg_acc_train, title = 'Acc train',plot_each_metric=False)\n",
    "    plot_stuff(q_avg_loss_train, title = 'Loss train',plot_each_metric=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38dee054",
   "metadata": {},
   "source": [
    "### Plot everything combined "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5efbf0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_stuff_combined(data_list, labels_list, title):\n",
    "    \n",
    "    plt.figure(figsize=(12,7))\n",
    "    for idx, data_ in enumerate(data_list):\n",
    "\n",
    "        data = data_.mean(axis=0)\n",
    "        std = data_.std(axis=0)\n",
    "\n",
    "        plt.title(title)\n",
    "\n",
    "        plt.plot(data, label=labels_list[idx])\n",
    "\n",
    "        plt.fill_between(range(len(data)), data - std, data + std, alpha=0.15)\n",
    "        \n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3a59f94",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# load classic metrics \n",
    "avg_acc_test = np.load('./metrics/resnet/avg_acc_test.npy')\n",
    "avg_acc_train = np.load('./metrics/resnet/avg_acc_train.npy')\n",
    "\n",
    "avg_loss_train = np.load('./metrics/resnet/avg_loss_train.npy')\n",
    "avg_loss_test = np.load('./metrics/resnet/avg_loss_test.npy')\n",
    "\n",
    "acc_test_list = []\n",
    "acc_train_list = []\n",
    "\n",
    "loss_test_list = []\n",
    "loss_train_list = []\n",
    "\n",
    "labels_list = []\n",
    "\n",
    "acc_test_list.append(avg_acc_test)\n",
    "acc_train_list.append(avg_acc_train)\n",
    "\n",
    "loss_test_list.append(avg_loss_test)\n",
    "loss_train_list.append(avg_loss_train)\n",
    "\n",
    "labels_list.append(\"Classic\")\n",
    "\n",
    "\n",
    "for q_depth in [1,5]:\n",
    "    \n",
    "    model_name=f\"resnet_q_angular_depth{q_depth}\"\n",
    "    \n",
    "    print(f'########## {model_name} ##########')\n",
    "\n",
    "    # load quantum metrics\n",
    "    avg_acc_test = np.load(f'./metrics/{model_name}/avg_acc_test.npy')\n",
    "    avg_acc_train = np.load(f'./metrics/{model_name}/avg_acc_train.npy')\n",
    "\n",
    "    avg_loss_train = np.load(f'./metrics/{model_name}/avg_loss_train.npy')\n",
    "    avg_loss_test = np.load(f'./metrics/{model_name}/avg_loss_test.npy')\n",
    "    \n",
    "    acc_test_list.append(avg_acc_test)\n",
    "    acc_train_list.append(avg_acc_train)\n",
    "\n",
    "    loss_test_list.append(avg_loss_test)\n",
    "    loss_train_list.append(avg_loss_train)\n",
    "    \n",
    "    labels_list.append(f\"Q_Resnet_depth_{q_depth}\")\n",
    "\n",
    "# plot in one plot\n",
    "plot_stuff_combined(acc_test_list, labels_list, title = 'Acc test')\n",
    "plot_stuff_combined(loss_test_list, labels_list, title = 'Loss test')\n",
    "\n",
    "plot_stuff_combined(acc_train_list, labels_list, title = 'Acc train')\n",
    "plot_stuff_combined(loss_train_list, labels_list, title = 'Loss train')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15aa37ce",
   "metadata": {},
   "source": [
    "### Train QNN with amplitude embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f20ec3a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_runs = 2\n",
    "num_epochs = 2\n",
    "for q_depth in [1]:\n",
    "\n",
    "    q_avg_acc_train, q_avg_acc_test, q_avg_loss_train, q_avg_loss_test = run_experiment(num_runs, num_epochs, nn_type = 'amplitude', q_depth = q_depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2ca1cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "!git status\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6db395bb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_braket",
   "language": "python",
   "name": "conda_braket"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
